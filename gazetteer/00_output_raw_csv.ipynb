{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.106492Z",
     "start_time": "2020-05-08T22:25:41.877553Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import regex\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.110242Z",
     "start_time": "2020-05-08T22:25:42.107639Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..') / 'data'\n",
    "RAW_DIR = DATA_DIR / '00_raw'\n",
    "INTERIM_DIR = DATA_DIR / '01_interim'\n",
    "\n",
    "ZIP = RAW_DIR / 'idigbio_all_2020-03-30.zip'\n",
    "DB = INTERIM_DIR / 'gazetteer_10_idigbio_2020-03-30.db'\n",
    "CSV = INTERIM_DIR / 'idigbio_2020-03-30c.csv'\n",
    "\n",
    "CHUNK = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.121119Z",
     "start_time": "2020-05-08T22:25:42.111391Z"
    }
   },
   "outputs": [],
   "source": [
    "if DB.exists():\n",
    "    os.remove(DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to use for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.130136Z",
     "start_time": "2020-05-08T22:25:42.123773Z"
    }
   },
   "outputs": [],
   "source": [
    "DWC_FIELDS = {f'dwc:{f}': f for f in \"\"\"\n",
    "    continent\n",
    "    coordinatePrecision\n",
    "    coordinateUncertaintyInMeters\n",
    "    country\n",
    "    countryCode\n",
    "    county\n",
    "    decimalLatitude\n",
    "    decimalLongitude\n",
    "    footprintSRS\n",
    "    footprintSpatialFit\n",
    "    footprintWKT\n",
    "    georeferencedDate\n",
    "    geodeticDatum\n",
    "    georeferencedBy\n",
    "    georeferenceProtocol\n",
    "    georeferenceremarks\n",
    "    georeferenceSources\n",
    "    georeferenceVerificationStatus\n",
    "    higherGeography\n",
    "    higherGeographyID\n",
    "    island\n",
    "    islandGroup\n",
    "    locality\n",
    "    locationID\n",
    "    locationRemarks\n",
    "    maximumDepthInMeters\n",
    "    maximumDistanceAboveSurfaceInMeters\n",
    "    maximumElevationInMeters\n",
    "    minimumDepthInMeters\n",
    "    minimumDistanceAboveSurfaceInMeters\n",
    "    minimumElevationInMeters\n",
    "    municipality\n",
    "    pointRadiusSpatialFit\n",
    "    stateProvince\n",
    "    verbatimCoordinateSystem\n",
    "    verbatimCoordinates\n",
    "    verbatimDepth\n",
    "    verbatimElevation\n",
    "    verbatimLatitude\n",
    "    verbatimLocality\n",
    "    verbatimLongitude\n",
    "    verbatimSRS\n",
    "    waterBody\n",
    "\"\"\".split()}\n",
    "\n",
    "\n",
    "IDIGBIO_FIELDS = {f'idigbio:{f}': f for f in \"\"\"\n",
    "    geoPoint\n",
    "    isoCountryCode\n",
    "\"\"\".split()}\n",
    "\n",
    "OTHER_FIELDS = {'coreid': 'coreid'}  # Need to link data\n",
    "\n",
    "FIELDS = {**OTHER_FIELDS, **DWC_FIELDS, **IDIGBIO_FIELDS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the headers from the zip file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.138677Z",
     "start_time": "2020-05-08T22:25:42.132222Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_headers(zip_file):\n",
    "    with zipfile.ZipFile(ZIP) as zippy:\n",
    "        with zippy.open(zip_file) as in_file:\n",
    "            headers = in_file.readline()\n",
    "    return [h.decode().strip() for h in sorted(headers.split(b','))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.145107Z",
     "start_time": "2020-05-08T22:25:42.139957Z"
    }
   },
   "outputs": [],
   "source": [
    "def insert(zip_file, usecols, columns):\n",
    "    table = zip_file.split('.')[0]\n",
    "\n",
    "    with sqlite3.connect(DB) as cxn:\n",
    "        with zipfile.ZipFile(ZIP) as zippy:\n",
    "            with zippy.open(zip_file) as in_file:\n",
    "\n",
    "                reader = pd.read_csv(\n",
    "                    in_file, dtype=str, keep_default_na=False,\n",
    "                    chunksize=CHUNK, usecols=usecols)\n",
    "\n",
    "                if_exists = 'replace'\n",
    "\n",
    "                for df in tqdm(reader):\n",
    "                    df = df.rename(columns=columns)\n",
    "\n",
    "                    df.to_sql(table, cxn,\n",
    "                              if_exists=if_exists, index=False)\n",
    "\n",
    "                    if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:25:42.153373Z",
     "start_time": "2020-05-08T22:25:42.147391Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrapper(zip_file):\n",
    "    headers = get_headers(zip_file)\n",
    "\n",
    "    usecols = [h for h in headers if h in FIELDS]\n",
    "    columns = {h: FIELDS[h] for h in usecols}\n",
    "\n",
    "    insert(zip_file, usecols, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T22:53:09.016308Z",
     "start_time": "2020-05-08T22:25:42.154857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [27:26, 13.50s/it]\n"
     ]
    }
   ],
   "source": [
    "wrapper('occurrence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T23:35:16.063563Z",
     "start_time": "2020-05-08T22:53:09.017411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [42:06, 20.71s/it]\n"
     ]
    }
   ],
   "source": [
    "wrapper('occurrence_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Update database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T23:39:22.499435Z",
     "start_time": "2020-05-08T23:35:16.068112Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    create index if not exists occ_coreid on occurrence (coreid);\n",
    "    create index if not exists raw_coreid on occurrence_raw (coreid);\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(DB) as cxn:\n",
    "    cxn.executescript(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T11:39:14.769720Z",
     "start_time": "2020-05-09T11:39:14.737603Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    alter table occurrence rename column isoCountryCode to idigbio_countrycode;\n",
    "    alter table occurrence add column idigbio_decimallatitude_wgs84;\n",
    "    alter table occurrence add column idigbio_decimallongitude_wgs84;\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(DB) as cxn:\n",
    "    cxn.executescript(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T11:47:34.963638Z",
     "start_time": "2020-05-09T11:42:32.863728Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    update occurrence\n",
    "       set idigbio_decimallatitude_wgs84  = json_extract(geoPoint, '$.lat'),\n",
    "           idigbio_decimallongitude_wgs84 = json_extract(geoPoint, '$.lon')\n",
    "     where geoPoint is not null\n",
    "       and geoPoint <> '';\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(DB) as cxn:\n",
    "    cxn.execute(sql)\n",
    "    cxn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T11:48:12.257500Z",
     "start_time": "2020-05-09T11:48:12.254791Z"
    }
   },
   "outputs": [],
   "source": [
    "if CSV.exists():\n",
    "    os.remove(CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T11:48:14.731314Z",
     "start_time": "2020-05-09T11:48:14.725607Z"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    select occurrence_raw.*,\n",
    "           idigbio_countrycode,\n",
    "           idigbio_decimallatitude_wgs84,\n",
    "           idigbio_decimallongitude_wgs84\n",
    "    from occurrence_raw\n",
    "    left join occurrence using (coreid);\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:41:34.748124Z",
     "start_time": "2020-05-09T11:48:19.830939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [53:14, 26.19s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(CSV, 'a') as out:\n",
    "    with sqlite3.connect(DB) as cxn:\n",
    "\n",
    "        reader = pd.read_sql(sql, cxn, chunksize=CHUNK)\n",
    "\n",
    "        header = True\n",
    "\n",
    "        for df in tqdm(reader):\n",
    "            df.to_csv(out, header=header, index=False)\n",
    "\n",
    "            header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:41:36.254083Z",
     "start_time": "2020-05-09T12:41:36.066637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coreid,continent,coordinatePrecision,coordinateUncertaintyInMeters,country,countryCode,county,decimalLatitude,decimalLongitude,footprintSRS,footprintSpatialFit,footprintWKT,geodeticDatum,georeferenceProtocol,georeferenceSources,georeferenceVerificationStatus,georeferencedBy,georeferencedDate,higherGeography,higherGeographyID,island,islandGroup,locality,locationID,locationRemarks,maximumDepthInMeters,maximumElevationInMeters,minimumDepthInMeters,minimumElevationInMeters,municipality,pointRadiusSpatialFit,stateProvince,verbatimCoordinateSystem,verbatimCoordinates,verbatimDepth,verbatimElevation,verbatimLatitude,verbatimLocality,verbatimLongitude,verbatimSRS,waterBody,idigbio_countrycode,idigbio_decimallatitude_wgs84,idigbio_decimallongitude_wgs84\r\n"
     ]
    }
   ],
   "source": [
    "!head -1 \"$CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:52:32.402771Z",
     "start_time": "2020-05-09T12:41:37.652865Z"
    }
   },
   "outputs": [],
   "source": [
    "!gzip \"$CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
