{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:39:25.556393Z",
     "start_time": "2020-03-16T21:39:25.554096Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:39:26.604436Z",
     "start_time": "2020-03-16T21:39:26.121308Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import csv\n",
    "import regex\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:39:26.760627Z",
     "start_time": "2020-03-16T21:39:26.752047Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA = Path('..') / 'data'\n",
    "RAW = DATA / '00_raw'\n",
    "PRUNED = DATA / '01_pruned'\n",
    "IN_DIR = DATA / 'input'\n",
    "OUT_DIR = DATA / 'output'\n",
    "\n",
    "DB = PRUNED / 'gazetteer.db'\n",
    "\n",
    "CHUNK = 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insects_idigbio/occurrence_raw data without lat/longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T20:45:56.063858Z",
     "start_time": "2020-03-09T20:45:56.057448Z"
    }
   },
   "outputs": [],
   "source": [
    "in_file = RAW / 'insects_idigbio' / 'occurrence_raw.csv.gz'\n",
    "out_file = IN_DIR / 'insects_idigbio_occurrence_raw_no_geo.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T20:50:54.958273Z",
     "start_time": "2020-03-09T20:45:57.232293Z"
    }
   },
   "outputs": [],
   "source": [
    "reader = pd.read_csv(in_file, dtype=str, chunksize=CHUNK)\n",
    "\n",
    "first_chunk = True\n",
    "for df in tqdm(reader):\n",
    "    has_loc = df['dwc:locality'].notna() | df['dwc:verbatimLocality'].notna()\n",
    "    df['dwc:decimalLatitude'] = (\n",
    "        pd.to_numeric(df['dwc:decimalLatitude'], errors='coerce'\n",
    "                      ).fillna(9999.9).astype(float))\n",
    "    df['dwc:decimalLongitude'] = (\n",
    "        pd.to_numeric(df['dwc:decimalLongitude'], errors='coerce'\n",
    "                      ).fillna(9999.9).astype(float))\n",
    "    has_lat = (df['dwc:decimalLatitude'].between(-90.0, 90.0)\n",
    "               & df['dwc:decimalLatitude'] != 0.0)\n",
    "    has_lng = (df['dwc:decimalLongitude'].between(-180.0, 180.0)\n",
    "               & df['dwc:decimalLongitude'] != 0.0)\n",
    "    keep = has_loc & ~(has_lat & has_lng)\n",
    "    df = df.loc[keep, :]\n",
    "\n",
    "    if first_chunk:\n",
    "        df.to_csv(out_file, index=False)\n",
    "    else:\n",
    "        df.to_csv(out_file, index=False, mode='a', header=False)\n",
    "    first_chunk = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get insects_gbif without lat/longs\n",
    "\n",
    "\n",
    "It looks like there is garbage data in this CSV file that Pandas cannot handle, so I need to use the Python CSV library. This can happen when people copy and paste Word documents into a data cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:39:31.883459Z",
     "start_time": "2020-03-16T21:39:31.875871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_file = RAW / 'insects_gbif' / '0017955-200127171203522.csv'\n",
    "out_file = IN_DIR / 'insects_gbif_no_geo.csv'\n",
    "\n",
    "csv.field_size_limit(10_000_000)  # There are some big fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:39:32.590826Z",
     "start_time": "2020-03-16T21:39:32.580694Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbifID',\n",
       " 'datasetKey',\n",
       " 'occurrenceID',\n",
       " 'kingdom',\n",
       " 'phylum',\n",
       " 'class',\n",
       " 'order',\n",
       " 'family',\n",
       " 'genus',\n",
       " 'species',\n",
       " 'infraspecificEpithet',\n",
       " 'taxonRank',\n",
       " 'scientificName',\n",
       " 'verbatimScientificName',\n",
       " 'verbatimScientificNameAuthorship',\n",
       " 'countryCode',\n",
       " 'locality',\n",
       " 'stateProvince',\n",
       " 'occurrenceStatus',\n",
       " 'individualCount',\n",
       " 'publishingOrgKey',\n",
       " 'decimalLatitude',\n",
       " 'decimalLongitude',\n",
       " 'coordinateUncertaintyInMeters',\n",
       " 'coordinatePrecision',\n",
       " 'elevation',\n",
       " 'elevationAccuracy',\n",
       " 'depth',\n",
       " 'depthAccuracy',\n",
       " 'eventDate',\n",
       " 'day',\n",
       " 'month',\n",
       " 'year',\n",
       " 'taxonKey',\n",
       " 'speciesKey',\n",
       " 'basisOfRecord',\n",
       " 'institutionCode',\n",
       " 'collectionCode',\n",
       " 'catalogNumber',\n",
       " 'recordNumber',\n",
       " 'identifiedBy',\n",
       " 'dateIdentified',\n",
       " 'license',\n",
       " 'rightsHolder',\n",
       " 'recordedBy',\n",
       " 'typeStatus',\n",
       " 'establishmentMeans',\n",
       " 'lastInterpreted',\n",
       " 'mediaType',\n",
       " 'issue']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# headers = !zcat \"$in_file\" | head -1\n",
    "headers = !head -1 \"$in_file\"\n",
    "headers = headers[0].split('\\t')\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T21:45:31.552808Z",
     "start_time": "2020-03-16T21:39:37.117562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0dbf1401754a59a10272d6c782072c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5639820: expected 50 fields, saw 74\\nSkipping line 5640136: expected 50 fields, saw 74\\nSkipping line 5640706: expected 50 fields, saw 74\\nSkipping line 5641012: expected 50 fields, saw 74\\nSkipping line 5641844: expected 50 fields, saw 74\\n'\n",
      "b'Skipping line 35119977: expected 50 fields, saw 72\\nSkipping line 35122783: expected 50 fields, saw 75\\nSkipping line 35126587: expected 50 fields, saw 52\\n'\n",
      "b'Skipping line 35156846: expected 50 fields, saw 53\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reader = pd.read_csv(\n",
    "    in_file, dtype=str, chunksize=CHUNK, sep='\\t',\n",
    "    error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "first_chunk = True\n",
    "for df in tqdm(reader):\n",
    "    # has_loc = df['locality'].notna() | df['verbatimLocality'].notna()\n",
    "    has_loc = df['locality'].notna()\n",
    "    df['decimalLatitude'] = (\n",
    "        pd.to_numeric(df['decimalLatitude'], errors='coerce'\n",
    "                      ).fillna(9999.9).astype(float))\n",
    "    df['decimalLongitude'] = (\n",
    "        pd.to_numeric(df['decimalLongitude'], errors='coerce'\n",
    "                      ).fillna(9999.9).astype(float))\n",
    "    has_lat = (df['decimalLatitude'].between(-90.0, 90.0)\n",
    "               & df['decimalLatitude'] != 0.0)\n",
    "    has_lng = (df['decimalLongitude'].between(-180.0, 180.0)\n",
    "               & df['decimalLongitude'] != 0.0)\n",
    "    keep = has_loc & ~(has_lat & has_lng)\n",
    "    df = df.loc[keep, :]\n",
    "\n",
    "    if first_chunk:\n",
    "        df.to_csv(out_file, index=False)\n",
    "    else:\n",
    "        df.to_csv(out_file, index=False, mode='a', header=False)\n",
    "    first_chunk = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:31:20.753503Z",
     "start_time": "2020-03-10T17:31:20.750370Z"
    }
   },
   "outputs": [],
   "source": [
    "unknown = ('unspecified', 'unknown')\n",
    "\n",
    "remove = regex.compile(r'(?<!\\d)[.,;/(){}\"\\'\\[\\]\\-](?!\\d)')\n",
    "\n",
    "sql = \"\"\"select * from places where norm = ?\"\"\"\n",
    "\n",
    "threshold = 0.1\n",
    "hi = 999.0\n",
    "lo = -hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match insects_idigbio/occurrence_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:55:47.693749Z",
     "start_time": "2020-03-10T17:55:47.687086Z"
    }
   },
   "outputs": [],
   "source": [
    "in_file = IN_DIR / 'insects_idigbio_occurrence_raw_no_geo.csv.gz'\n",
    "out_file = OUT_DIR / 'insects_idigbio_no_geo_2020-03-10a.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:55:49.317805Z",
     "start_time": "2020-03-10T17:55:48.353513Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_file, dtype=str).fillna('')\n",
    "print([c for c in df.columns])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:56:07.794635Z",
     "start_time": "2020-03-10T17:55:50.593347Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lat'] = None\n",
    "df['lng'] = None\n",
    "df['datum'] = None\n",
    "df['uncert'] = None\n",
    "\n",
    "with sqlite3.connect(DB) as cxn:\n",
    "    cxn.row_factory = sqlite3.Row\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        for field in ['dwc:locality', 'dwc:verbatimLocality']:\n",
    "            loc = row[field]\n",
    "            loc = remove.sub(' ', loc)\n",
    "            loc = ' '.join(loc.lower().split())\n",
    "            if loc in unknown:\n",
    "                continue\n",
    "\n",
    "            hits = cxn.execute(sql, (loc, ))\n",
    "\n",
    "            has_datum_uncert = []\n",
    "            has_datum = []\n",
    "            has_uncert = []\n",
    "            neither = []\n",
    "            min_lat = hi\n",
    "            max_lat = lo\n",
    "            min_lng = hi\n",
    "            max_lng = lo\n",
    "            for hit in hits:\n",
    "                lat = round(hit[1], 4)\n",
    "                lng = round(hit[2], 4)\n",
    "                datum = hit['datum']\n",
    "                uncert = hit['uncert']\n",
    "                # print(loc, lat, lng, datum, uncert)\n",
    "                if datum and uncert:\n",
    "                    has_datum_uncert.append((lat, lng, datum, uncert))\n",
    "                elif datum:\n",
    "                    has_datum.append((lat, lng, datum, uncert))\n",
    "                elif uncert:\n",
    "                    has_uncert.append((lat, lng, datum, uncert))\n",
    "                else:\n",
    "                    neither.append((lat, lng, datum, uncert))\n",
    "                min_lat = min(min_lat, lat)\n",
    "                max_lat = max(max_lat, lat)\n",
    "                min_lng = min(min_lng, lng)\n",
    "                max_lng = max(max_lng, lng)\n",
    "            if max_lat - min_lat >= threshold:\n",
    "                continue\n",
    "            if max_lng - min_lng >= threshold:\n",
    "                continue\n",
    "            if has_datum_uncert:\n",
    "                df.at[idx, 'lat'] = has_datum_uncert[0][0]\n",
    "                df.at[idx, 'lng'] = has_datum_uncert[0][1]\n",
    "                df.at[idx, 'datum'] = has_datum_uncert[0][2]\n",
    "                df.at[idx, 'uncert'] = has_datum_uncert[0][3]\n",
    "                break\n",
    "            elif has_datum:\n",
    "                df.at[idx, 'lat'] = has_datum[0][0]\n",
    "                df.at[idx, 'lng'] = has_datum[0][1]\n",
    "                df.at[idx, 'datum'] = has_datum[0][2]\n",
    "                df.at[idx, 'uncert'] = has_datum[0][3]\n",
    "                break\n",
    "            elif has_uncert:\n",
    "                df.at[idx, 'lat'] = has_uncert[0][0]\n",
    "                df.at[idx, 'lng'] = has_uncert[0][1]\n",
    "                df.at[idx, 'datum'] = has_uncert[0][2]\n",
    "                df.at[idx, 'uncert'] = has_uncert[0][3]\n",
    "                break\n",
    "            elif neither:\n",
    "                df.at[idx, 'lat'] = neither[0][0]\n",
    "                df.at[idx, 'lng'] = neither[0][1]\n",
    "                df.at[idx, 'datum'] = neither[0][2]\n",
    "                df.at[idx, 'uncert'] = neither[0][3]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:56:10.784641Z",
     "start_time": "2020-03-10T17:56:10.769655Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['dwc:locality', 'dwc:verbatimLocality', 'lat', 'lng', 'datum', 'uncert']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:56:18.987693Z",
     "start_time": "2020-03-10T17:56:16.106091Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:56:19.264531Z",
     "start_time": "2020-03-10T17:56:18.988875Z"
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T15:14:06.933746Z",
     "start_time": "2020-03-18T15:14:06.925941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(10302 / 50020 * 100.0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match insects_gbif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:56:26.101501Z",
     "start_time": "2020-03-10T17:56:26.099359Z"
    }
   },
   "outputs": [],
   "source": [
    "in_file = IN_DIR / 'insects_gbif_no_geo.csv.gz'\n",
    "out_file = OUT_DIR / 'insects_gbif_no_geo_2020-03-10a.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:57:24.756268Z",
     "start_time": "2020-03-10T17:56:27.110856Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_file, dtype=str).fillna('')\n",
    "print([c for c in df.columns])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T18:31:02.607002Z",
     "start_time": "2020-03-10T17:57:28.207997Z"
    }
   },
   "outputs": [],
   "source": [
    "df['lat'] = None\n",
    "df['lng'] = None\n",
    "df['datum'] = None\n",
    "df['uncert'] = None\n",
    "\n",
    "with sqlite3.connect(DB) as cxn:\n",
    "    cxn.row_factory = sqlite3.Row\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        for field in ['locality', ]:\n",
    "            loc = row[field]\n",
    "            loc = remove.sub(' ', loc)\n",
    "            loc = ' '.join(loc.lower().split())\n",
    "            if loc in unknown:\n",
    "                continue\n",
    "\n",
    "            hits = cxn.execute(sql, (loc, ))\n",
    "\n",
    "            has_datum_uncert = []\n",
    "            has_datum = []\n",
    "            has_uncert = []\n",
    "            neither = []\n",
    "            min_lat = hi\n",
    "            max_lat = lo\n",
    "            min_lng = hi\n",
    "            max_lng = lo\n",
    "            for hit in hits:\n",
    "                lat = round(hit[1], 4)\n",
    "                lng = round(hit[2], 4)\n",
    "                datum = hit['datum']\n",
    "                uncert = hit['uncert']\n",
    "                # print(loc, lat, lng, datum, uncert)\n",
    "                if datum and uncert:\n",
    "                    has_datum_uncert.append((lat, lng, datum, uncert))\n",
    "                elif datum:\n",
    "                    has_datum.append((lat, lng, datum, uncert))\n",
    "                elif uncert:\n",
    "                    has_uncert.append((lat, lng, datum, uncert))\n",
    "                else:\n",
    "                    neither.append((lat, lng, datum, uncert))\n",
    "                min_lat = min(min_lat, lat)\n",
    "                max_lat = max(max_lat, lat)\n",
    "                min_lng = min(min_lng, lng)\n",
    "                max_lng = max(max_lng, lng)\n",
    "            if max_lat - min_lat >= threshold:\n",
    "                continue\n",
    "            if max_lng - min_lng >= threshold:\n",
    "                continue\n",
    "            if has_datum_uncert:\n",
    "                df.at[idx, 'lat'] = has_datum_uncert[0][0]\n",
    "                df.at[idx, 'lng'] = has_datum_uncert[0][1]\n",
    "                df.at[idx, 'datum'] = has_datum_uncert[0][2]\n",
    "                df.at[idx, 'uncert'] = has_datum_uncert[0][3]\n",
    "                break\n",
    "            elif has_datum:\n",
    "                df.at[idx, 'lat'] = has_datum[0][0]\n",
    "                df.at[idx, 'lng'] = has_datum[0][1]\n",
    "                df.at[idx, 'datum'] = has_datum[0][2]\n",
    "                df.at[idx, 'uncert'] = has_datum[0][3]\n",
    "                break\n",
    "            elif has_uncert:\n",
    "                df.at[idx, 'lat'] = has_uncert[0][0]\n",
    "                df.at[idx, 'lng'] = has_uncert[0][1]\n",
    "                df.at[idx, 'datum'] = has_uncert[0][2]\n",
    "                df.at[idx, 'uncert'] = has_uncert[0][3]\n",
    "                break\n",
    "            elif neither:\n",
    "                df.at[idx, 'lat'] = neither[0][0]\n",
    "                df.at[idx, 'lng'] = neither[0][1]\n",
    "                df.at[idx, 'datum'] = neither[0][2]\n",
    "                df.at[idx, 'uncert'] = neither[0][3]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T18:37:26.550054Z",
     "start_time": "2020-03-10T18:37:26.352067Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['locality', 'lat', 'lng', 'datum', 'uncert']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T18:39:47.590611Z",
     "start_time": "2020-03-10T18:37:35.953211Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T18:39:57.233334Z",
     "start_time": "2020-03-10T18:39:47.591803Z"
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T15:14:12.558145Z",
     "start_time": "2020-03-18T15:14:12.555170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(968681 / 6016843 * 100.0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
